\section{Kritische Refelexion Auth-Service}
Die oben geschilderte Implementierung des Auth-Service reflektiert mehrere sicherheitsrelevante und architekturelle Entscheidungen:
\begin{enumerate}
    \item HMAC-basierte PSK-Verifikation: Die Wahl eines Challenge-Response-Verfahrens mit HMAC stellt sicher, dass ein Gerätegeheimnis nicht direkt übertragen wird, sondern nur indirekt bewiesen. Der Auth-Service speichert Tokens gesalzen (mittels TOKEN\_SECRET) als Hash in seiner Config, was grundsätzlich ein Sicherheitsvorteil ist. Allerdings verbleibt das Token zusätzlich im Klartext in der Konfigurationsdatei, was im Widerspruch zu bewährten Sicherheitsprinzipien steht – es wäre ausreichend, nur den Hash zu persistieren und das Token nach Ausgabe zu verwerfen\cite{pskDesign}.
    \item Kopplung mit Systemdatenbank: Die referenzielle Konsistenz durch Verknüpfung von Controller und User in der Datenbank unterstützt zentrale Anforderungspunkte. Jedoch erhöht sich dadurch auch die Kopplung einzelner Komponenten, was bei Änderungen im Datenbankschema zu potenziellen Wartungsaufwänden führen kann.
    \item Automatisierte Broker-Provisionierung: Die dynamische Benutzer- und ACL-Erstellung über die Solace SEMPv2 API bietet hohe Flexibilität und Skalierbarkeit. Die Implementierung reagiert korrekt auf typische Statuscodes wie HTTP 409, bleibt jedoch ohne Transaktionsmechanismen anfällig für inkonsistente Zustände, falls einzelne Schritte des Provisionierungsprozesses scheitern. Eine explizite Fehlerbehandlung für Teilausfälle wäre hier sinnvoll.
    \item Sichere Auslieferung von Secrets: Die Übertragung der Broker-Zugangsdaten erfolgt verschlüsselt und signiert, wodurch ein zusätzlicher Schutzlayer entsteht. Dennoch erfolgt die Übertragung des temporären Session Keys im Klartext (wenn auch signiert), was gegenüber klassischen Key-Exchange-Protokollen eine reduzierte Sicherheit darstellt. Angesichts des bestehenden PSK stellt dies jedoch eine pragmatische, wenn auch nicht optimale Lösung dar.
    \item Fehlerbehandlung und Logging: Die granulare Fehlerdifferenzierung und das konsistente Logging tragen zur Transparenz und Diagnosefähigkeit bei. In produktiven Szenarien könnte jedoch ein zentralisiertes Log-Management hilfreich sein, um sicherheitsrelevante Ereignisse auswertbar zu halten.
\end{enumerate}

Zusammenfassend realisiert der Auth-Service die in den Anforderungen definierte Geräteauthentifizierung durch einen robusten, mehrschrittigen Prozess. Die Verwendung etablierter Kryptographie (HMAC-SHA256, AES-basierte Fernet-Verschlüsselung) in Kombination mit einer modularen Architektur erfüllt die Sicherheits- und Skalierbarkeitsanforderungen. Einzelne sicherheitsrelevante Details, wie die Speicherung von Tokens im Klartext und fehlende Transaktionslogik bei der Broker-Provisionierung, sollten jedoch überarbeitet werden.
\section{Kritische Reflexion Mailservice}
Einige besondere Aspekte und Entscheidungen des Mail-Service:
\begin{enumerate}
    \item Einsatz von FastAPI und Async DB: Die Wahl von FastAPI und asyncpg ermöglicht performante, nicht-blockierende Datenbankabfragen. Die Verwendung einer lifespan-Funktion zur Initialisierung der Datenbankverbindung ist effizient. Dennoch fehlt eine Absicherung gegen potenzielle Verbindungsverluste zur Laufzeit – ein automatischer Reconnect-Mechanismus wäre für höhere Robustheit wünschenswert.
    \item Preshared Service Key (PSK) für /verify: Der PSK-Mechanismus schützt den sensiblen Verifikationsendpunkt wirkungsvoll gegen unautorisierte Aufrufe. In der gegebenen Architektur ist der statische Schlüssel praktikabel, für größere Systeme oder Produktionsumgebungen wäre jedoch ein zeitlich begrenzter, rotierender Schlüssel oder ein dedizierter Auth-Service vorzuziehen.
    \item Token-Generierung und -Speicherung: Die Token-Erzeugung mit \\ \texttt{secrets.token\_urlsafe} erfüllt kryptografische Anforderungen. Die ausschließliche Speicherung im RAM (Python Dictionary) vermeidet Persistenzprobleme, führt jedoch zu Verlust bei Dienstneustart. Dies kann in Szenarien mit hoher Verifikationslatenz problematisch sein. Eine persistente Speicherung in der Nutzerdatenbank wäre hier langfristig robuster.
    \item Aktivierung des Benutzerkontos: Die Kapselung der Account-Aktivierung im Service ist gelungen. Jedoch gibt es keine Validierung, ob das Token bereits abgelaufen oder mehrfach genutzt wurde. Eine Ergänzung um zeitbasierte Gültigkeit oder Einmaligkeit wäre zur Erhöhung der Sicherheit empfehlenswert.
    \item Versand per SMTP: Die Entscheidung, den Mailversand über SMTP und smtplib selbst zu realisieren, ist nachvollziehbar, aber mit gewissen Risiken verbunden. Die Nutzung eines persönlichen Gmail-Kontos sowie die fehlende Wiederholungslogik bei Versandfehlern (z.B. temporärer SMTP-Ausfall) schränken die Zuverlässigkeit und Sicherheit ein. Für produktive Umgebungen wäre ein externer Maildienst mit stabiler API und Fehlerbehandlung vorzuziehen.
    \item Feedback an den Nutzer: Die Rückmeldung nach erfolgreicher Verifikation erfolgt korrekt, ist jedoch funktional und gestalterisch minimalistisch gehalten. Eine klarere Benutzerführung – etwa durch Weiterleitung in die Hauptanwendung – könnte die Nutzererfahrung verbessern.
\end{enumerate}

Durch die Entkopplung des E-Mail-Versands in einen eigenen Microservice bleibt die Verantwortung klar getrennt. Die Umsetzung ist funktional und erfüllt die Grundanforderungen. Verbesserungsbedarf besteht insbesondere bei der Tokenpersistenz und SMTP-Fehlertoleranz, um den Dienst in produktiven Szenarien zuverlässig betreiben zu können.

\section{Kritische Reflexion Database Writer}
Eine entscheidende Stärke dieser Implementierung ist die Nutzung der persistenten Solace-Queue. Dadurch wird das Prinzip der garantierten Zustellung (Guaranteed Delivery) zuverlässig umgesetzt. Dennoch gibt es einige Punkte, die kritisch hinterfragt werden können:
\begin{enumerate}
    \item Die Inserts der Messwerte basieren auf einem at-least-once-Verarbeitungsmuster. Während dies grundsätzlich sinnvoll ist, fehlen dedizierte Mechanismen zur Dublettenvermeidung auf Werteebene. Das System verlässt sich auf die Einzigartigkeit der \texttt{vid}, wodurch bei Redelivery identische Messwerte mehrfach gespeichert werden können. In produktiven Szenarien könnte dies zu Datenverzerrungen führen. Eine explizite Deduplikationsstrategie – etwa über kombinierte Primärschlüssel oder Hashing der Payload – wäre wünschenswert.
    \item Die Idempotenz bei der Sensoranlage wird nur durch die sequenzielle Abarbeitung im Single-Thread sichergestellt. Dies funktioniert im aktuellen Setup, skaliert jedoch nicht ohne weiteres auf parallele Consumer. Eine atomare Datenbankoperation (z.B. \texttt{INSERT ON CONFLICT DO NOTHING}) wäre hier robuster.
    \item Die Statusverwaltung des Sensors (z.B. Wechsel zu 'error') ist funktional implementiert, jedoch in der Logik sehr spezifisch auf einen 5-Minuten-Zeitraum beschränkt. Eine flexiblere, konfigurierbare Lösung – z.B. ein Watchdog-Modul mit Schwellenwerten – könnte das System anpassungsfähiger machen.
    \item Bei Ausfällen der Datenbank wird keine explizite Retry-Strategie verfolgt. Das aktuelle Verhalten – Rückgabe von \texttt{None} und Verzicht auf Ack – ist korrekt und verhindert Datenverlust. Jedoch erfolgt keine gezielte Behandlung der hängengebliebenen Nachrichten, etwa durch automatisiertes Requeueing oder Logging für spätere Analyse. Eine gezielte Fehlerbehandlung (z.B. persistente Dead-Letter-Queue) könnte hier mehr Transparenz und Kontrolle schaffen.
    \item Die Logging-Strategie mit leicht menschenlesbarer Struktur erleichtert die Entwicklung und Analyse. Für eine produktive Umgebung fehlen jedoch strukturierte Logs (z.B. JSON), die von externen Tools (wie ELK oder Grafana Loki) verarbeitet werden könnten. Zudem fehlt eine Differenzierung nach Komponenten, um z.B. zwischen Netzwerkfehlern und Datenbankproblemen besser zu unterscheiden.
\end{enumerate}

Im Rahmen dieser Arbeit zeigt sich, dass der Service zuverlässig und fehlertolerant arbeitet. Die grundlegenden Prinzipien – insbesondere die Trennung von Empfang und Persistenz durch Messaging – sind sinnvoll umgesetzt. Für den produktiven Betrieb wären allerdings Verbesserungen bei Idempotenz, Fehlerbehandlung und Logging erforderlich, um Skalierbarkeit und Betriebssicherheit langfristig zu gewährleisten.

\section{Kritische Reflexion Setpoint-API}
Der Setpoint-Service ist relativ einfach gestrickt, dennoch gibt es einige bemerkenswerte Punkte:
\begin{enumerate}
    \item Flask mit Swagger: Ähnlich dem Auth-Service wurde hier Flask verwendet, ergänzt um Flasgger für die API-Dokumentation. Somit kann auch dieser Service seine Schnittstelle (Parameter, Responses) im Swagger-UI darstellen. Die Entscheidung für Flask (anstelle von FastAPI) erscheint aus Konsistenzgründen nachvollziehbar, birgt jedoch Einschränkungen hinsichtlich asynchroner Verarbeitung. Zwar spielt dies im aktuellen Anwendungsfall keine Rolle, langfristig wäre eine einheitliche, moderne Technologieplattform vorteilhaft.
    \item Broker-Konnektivität: Der Service initialisiert beim Start eine Verbindung zum Solace-Broker und erzeugt einen persistenten Publisher. Sollte der Broker zu diesem Zeitpunkt nicht verfügbar sein, wird durch die Retry-Schleife ein erneuter Verbindungsversuch unternommen. Allerdings fehlt eine Statusüberwachung der Verbindung zur Laufzeit. Ein unerwarteter Verbindungsabbruch könnte dazu führen, dass der Service Anfragen annimmt, aber keine Nachrichten mehr versenden kann. Dies müsste entweder aktiv überwacht oder durch geeignete Fehlerbehandlung im Code abgesichert werden.
    \item Payload-Struktur und Flexibilität: Die aktuelle Struktur erwartet, dass Controller- und Sensor-ID direkt übergeben werden. Die angedeutete Weiterentwicklung, diese IDs aus der Datenbank zu ermitteln, wurde bislang nicht umgesetzt. Dies führt zu einer potenziellen Fehlerquelle, wenn fehlerhafte Zuordnungen gemacht werden. Eine stärkere Entkopplung und Validierung anhand der DB wäre hier ein Qualitätsgewinn – insbesondere im Hinblick auf die korrekte Adressierung von Geräten.
    \item Security und Authentifizierung: Der Service verfügt über keinerlei Authentifizierungsmechanismus. In einer offenen Netzwerkumgebung stellt dies ein erhebliches Risiko dar: Jeder, der über die nötigen IDs verfügt, könnte Steuerbefehle an beliebige Controller senden. Auch wenn davon ausgegangen wird, dass eine vorgelagerte Authentifizierung existiert, sollte der Service zumindest ein optionales Authentifizierungsverfahren unterstützen (z.B. API-Key, JWT). Das Fehlen einer solchen Sicherung steht im Widerspruch zur sonst hohen Sicherheitsorientierung des Gesamtsystems.
    \item Themenpersistenz: Die vom Auth-Service gesetzten ACLs verhindern erfolgreich, dass Nachrichten an unautorisierte Controller übermittelt werden. Dies schützt zwar den Empfangsweg, verhindert jedoch nicht, dass falsche Sollwerte vom falschen Benutzer initiiert werden. Zudem basiert das Zustellmodell ausschließlich auf MQTT-Mechanismen. Die Möglichkeit zur Nutzung von Queues zur Bestätigung oder Rückmeldung wurde bislang nicht implementiert. Das könnte bei sicherheitskritischen Steuerbefehlen ein relevantes Defizit sein.
    \item Fehlerbehandlung und Benutzerfeedback: Die Rückmeldungen an den Aufrufer sind funktional, aber minimalistisch. Im Fehlerfall wird lediglich eine Exception geworfen, die zu einem HTTP 500 führt. Eine genauere Differenzierung von Fehlertypen (z.B. ungültige IDs, Broker nicht erreichbar) wäre für Client-Systeme hilfreich. Auch ein Retry-Konzept bei temporären Fehlern könnte die Zuverlässigkeit verbessern.
    \item Relevanz zum Gesamtsystem: Die Setpoint API realisiert einen der in der Einleitung geforderten Interface-Services. Sie ist relativ unabhängig von den anderen – außer dass sie natürlich von der existierenden Broker-Infrastruktur und der Auth vorher eingerichteten ACL profitiert. Ohne Auth-Service hätte der Controller kein Broker-Login oder keine Subscription. Hier sieht man schön die Arbeitsteilung: Der Auth-Service bereitet das System so vor, dass Controller Messwerte liefern und Sollwerte empfangen dürfen. Die Setpoint API nutzt diese vorbereitete Bahn, um auf einfache Weise Nachrichten an Geräte zu schicken, ohne jeden Controller einzeln zu kennen (außer über die ID).
\end{enumerate}

Das gewählte REST-zu-MQTT-Muster ist gängig in IoT-Architekturen: Es erlaubt z.B. einer Webanwendung per HTTP (wofür es viele Tools/SDKs gibt) mit einem IoT-Gerät zu kommunizieren, das nur MQTT spricht, über einen Vermittlungsbroker. Dennoch zeigen sich bei der aktuellen Implementierung mehrere Schwächen im Hinblick auf Authentifizierung, Validierung und Fehlertoleranz. Diese sollten im weiteren Verlauf adressiert werden, um die Sicherheit und Robustheit der Kommunikation zu gewährleisten.
\section{Kritische Reflexion Solace-Init}
Solace Init stellt sicher, dass die notwendige Broker-Umgebung programmgesteuert hergestellt wird, ohne manuelle Schritte in der Solace-Admin-Oberfläche. Dies ist aus mehreren Gründen vorteilhaft:
\begin{enumerate}
    \item Automatisierung: In containerisierten Deployments können so neue Umgebungen hochgefahren werden und sind sofort lauffähig, weil die benötigten Infrastruktur-Komponenten (Warteschlangen) automatisch erzeugt werden. Der Infrastructure-as-Code-Gedanke wird hier konsequent umgesetzt – die JSON-Datei fungiert als zentrale Konfigurationsquelle. Eine gewisse Einschränkung besteht jedoch darin, dass die Warteschlange und Subscriptions ausschließlich zum Initialzeitpunkt erzeugt werden. Eine dynamische Reaktion auf Laufzeitänderungen (z.B. neue Topics) ist im aktuellen Design nicht vorgesehen.
    \item Konsistenz: Es wird sichergestellt, dass z.B. die sensor\_data Queue wirklich existiert, bevor andere Services (Database Writer) damit arbeiten. Die Verwendung von Compose depends\_on allein reicht nicht aus, um dies zu garantieren. Solace Init füllt diese Lücke, indem es nach einer festen Wartezeit die Einrichtung vornimmt. Diese Wartezeit ist jedoch statisch gewählt und könnte bei langsamen Systemstarts zu einem Rennen führen – hier wäre eine robuste Verfügbarkeitsprüfung des Brokers vorzuziehen.
    \item Wiederholbarkeit: Durch die Abfrage der HTTP-Antwort (409 → "existiert bereits") ist das Skript idempotent. Man kann es gefahrlos erneut laufen lassen, etwa nach einem Broker-Neustart, ohne Duplikate zu erzeugen. Dies erleichtert Updates – z.B. kann ein neues Topic zur JSON-Datei hinzugefügt und das Skript erneut ausgeführt werden. Einschränkend bleibt jedoch festzuhalten, dass die Lösung keine Validierung bestehender Konfigurationen vornimmt: Änderungen (z.B. an ACLs) werden nicht überprüft oder aktualisiert, sondern nur ergänzt. Eine differenziertere Änderungsstrategie wäre für langfristige Wartbarkeit hilfreich.
\end{enumerate}

Der Code von Solace Init ist bewusst einfach gehalten. Er verzichtet z.B. auf einen ständigen Daemon – er braucht nur einmal zu Beginn laufen. Ein kleiner Nachteil dieser Einfachheit: Wenn nachträglich (zur Laufzeit) neue Controller angelegt werden, könnten diese evtl. zusätzliche Topics erfordern. Allerdings deckt unser Modell das dynamisch über ACLs ab, nicht über Queues – neue Controller publizieren auf vorhandenes Muster \texttt{sensora/v1/send/<id>}, was durch den Wildcard \texttt{>} der bestehenden Subscription bereits erfasst ist. Somit muss man Solace Init nur erneut laufen lassen, wenn man das generelle Muster ändern würde. Dennoch wäre eine fortlaufende Integration mit der Controller-Verwaltung denkbar, etwa durch ein Triggern von Solace Init bei Anlage neuer Controller, um zukünftige Erweiterungen vollständig abzubilden.


